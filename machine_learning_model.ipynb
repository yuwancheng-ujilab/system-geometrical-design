{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation , BatchNormalization, Dropout\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "#set the path for this code\n",
    "path=r'xxx'\n",
    "os.chdir(path)\n",
    "\n",
    "#Timing\n",
    "start = time.time()\n",
    "\n",
    "#preprocessing of raw data\n",
    "x_min_max_scaler = preprocessing.MinMaxScaler()\n",
    "y_min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "#save the result\n",
    "result_dir = 'result'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.mkdir(result_dir)\n",
    "    \n",
    "#get data from the previous generated data file\n",
    "train_data = np.load(r'.\\train_data\\traindata.npy')\n",
    "vali_data = np.load(r'.\\train_data\\validata.npy')\n",
    "test_data = np.load(r'.\\train_data\\testdata.npy')\n",
    "\n",
    "#divide x and y\n",
    "x_train = train_data[:,[0,1,2,3,4,5,6,7,8]]\n",
    "y_train = train_data[:,[9,10,11,12]]\n",
    "x_vali = vali_data[:,[0,1,2,3,4,5,6,7,8]]\n",
    "y_vali = vali_data[:,[9,10,11,12]]\n",
    "x_test = test_data[:,[0,1,2,3,4,5,6,7,8]]\n",
    "y_test = test_data[:,[9,10,11,12]]\n",
    "\n",
    "#standardScaler\n",
    "x_train_std = x_min_max_scaler.fit_transform(x_train)\n",
    "y_train_std = y_min_max_scaler.fit_transform(y_train)\n",
    "x_vali_std = x_min_max_scaler.transform(x_vali)\n",
    "y_vali_std = y_min_max_scaler.transform(y_vali)\n",
    "x_test_std = x_min_max_scaler.transform(x_test)\n",
    "y_test_std = y_min_max_scaler.transform(y_test)\n",
    "\n",
    "#save the model of preprocessing\n",
    "clf_x = x_min_max_scaler\n",
    "clf_y = y_min_max_scaler\n",
    "dump(clf_x, \"stsc/stsc_x.joblib\")\n",
    "dump(clf_y, \"stsc/stsc_y.joblib\")\n",
    "\n",
    "#layer number, node number can be changed based on the performance of machine learning model\n",
    "#batchnormalization and dropout can also be appllied based on the performance\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128,input_shape=(9,)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "#model.add(Dense(128))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.3)),\n",
    "\n",
    "model.add(Dense(4)) \n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "\n",
    "#---------------train data+test data-------------------\n",
    "#batch size and epochs can be changed based on the performance\n",
    "\n",
    "hist1=model.fit(x_train_std, y_train_std, batch_size=1024, epochs=3000, verbose=1, validation_data=(x_vali_std,y_vali_std))\n",
    "loss = model.evaluate(x_test_std, y_test_std, verbose=1)\n",
    "print(loss)\n",
    "\n",
    "#possible early stop\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=40, verbose=0, mode='auto')\n",
    "#hist1 = model.fit(x_train_std, y_train_std, epochs=300, batch_size=256, verbose=2,\n",
    "#                    validation_data=(x_test_std, y_test_std), callbacks=[early_stopping])\n",
    "#loss = model.evaluate(x_test_std, y_test_std, verbose=0)\n",
    "#print(loss)\n",
    "\n",
    "\n",
    "#-------------------save model-------------------\n",
    "json_string = model.to_json()\n",
    "open(os.path.join(result_dir, 'model.json'), 'w').write(json_string)\n",
    "model.save(os.path.join(result_dir, 'model.h5'))\n",
    "\n",
    "#-------------------save weights----------------------\n",
    "model.save_weights(os.path.join(result_dir, 'weights.h5'))\n",
    "\n",
    "#------------------plot-------------------------\n",
    "plt.plot(hist1.history['loss'], color='b', linewidth=2, label='training')\n",
    "plt.plot(hist1.history['val_loss'], color='r', linewidth=1, label='validation')\n",
    "\n",
    "#y_pred=model.predict(x_test_std)\n",
    "#msepred = mean_squared_error(y_test_std, y_pred)\n",
    "#print(msepred)\n",
    "#plt.plot(y_test_std,y_pred)\n",
    "\n",
    "#print the loss figure\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.yscale('log')\n",
    "plt.savefig(\"loss.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
